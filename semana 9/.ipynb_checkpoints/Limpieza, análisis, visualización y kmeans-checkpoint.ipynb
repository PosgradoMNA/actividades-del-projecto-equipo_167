{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actividad Semanal -- 4\n",
    "\n",
    "Genaro Rodriguez Vazquez A01150931\n",
    "\n",
    "Javier Rodríguez Rudas A01793817\n",
    "\n",
    "Ciencia y analítica de Datos\n",
    "\n",
    "Profesor: Dr. Jobish Vallikavungal Devassia  \n",
    "\n",
    "10 Octubre 2022\n",
    "\n",
    "\tVamos a reutilizar el codigo de la sesion pasada, pues en dicho ejercicio hicimos la conexion a la fuente de datos, y eliminamos aquellos registros que podrian afectar nuestro calculo. A su vez, le dimos algo de formato.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#For pipeline creation\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "#For scoring RMSE, MAE y MAPE\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import classification_report, make_scorer\n",
    "from sklearn.model_selection import cross_validate \n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# models from sklearn to test\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "#Gridsearch and importance\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn.preprocessing import power_transform\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import math as math\n",
    "\n",
    "\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
    "from sklearn.model_selection import learning_curve, validation_curve\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import RocCurveDisplay   \n",
    "from sklearn.metrics import roc_curve,plot_roc_curve, balanced_accuracy_score\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SITIO</th>\n",
       "      <th>ORGANISMO_DE_CUENCA</th>\n",
       "      <th>ESTADO</th>\n",
       "      <th>MUNICIPIO</th>\n",
       "      <th>ACUIFERO</th>\n",
       "      <th>SUBTIPO</th>\n",
       "      <th>LONGITUD</th>\n",
       "      <th>LATITUD</th>\n",
       "      <th>PERIODO</th>\n",
       "      <th>ALC_mg/L</th>\n",
       "      <th>CALIDAD_ALC</th>\n",
       "      <th>CONDUCT_mS/cm</th>\n",
       "      <th>CALIDAD_CONDUC</th>\n",
       "      <th>SDT_mg/L</th>\n",
       "      <th>SDT_M_mg/L</th>\n",
       "      <th>CALIDAD_SDT_ra</th>\n",
       "      <th>CALIDAD_SDT_salin</th>\n",
       "      <th>FLUORUROS_mg/L</th>\n",
       "      <th>CALIDAD_FLUO</th>\n",
       "      <th>DUR_mg/L</th>\n",
       "      <th>CALIDAD_DUR</th>\n",
       "      <th>COLI_FEC_NMP/100_mL</th>\n",
       "      <th>CALIDAD_COLI_FEC</th>\n",
       "      <th>N_NO3_mg/L</th>\n",
       "      <th>CALIDAD_N_NO3</th>\n",
       "      <th>AS_TOT_mg/L</th>\n",
       "      <th>CALIDAD_AS</th>\n",
       "      <th>CD_TOT_mg/L</th>\n",
       "      <th>CALIDAD_CD</th>\n",
       "      <th>CR_TOT_mg/L</th>\n",
       "      <th>CALIDAD_CR</th>\n",
       "      <th>HG_TOT_mg/L</th>\n",
       "      <th>CALIDAD_HG</th>\n",
       "      <th>PB_TOT_mg/L</th>\n",
       "      <th>CALIDAD_PB</th>\n",
       "      <th>MN_TOT_mg/L</th>\n",
       "      <th>CALIDAD_MN</th>\n",
       "      <th>FE_TOT_mg/L</th>\n",
       "      <th>CALIDAD_FE</th>\n",
       "      <th>SEMAFORO</th>\n",
       "      <th>CONTAMINANTES</th>\n",
       "      <th>CUMPLE_CON_ALC</th>\n",
       "      <th>CUMPLE_CON_COND</th>\n",
       "      <th>CUMPLE_CON_SDT_ra</th>\n",
       "      <th>CUMPLE_CON_SDT_salin</th>\n",
       "      <th>CUMPLE_CON_FLUO</th>\n",
       "      <th>CUMPLE_CON_DUR</th>\n",
       "      <th>CUMPLE_CON_CF</th>\n",
       "      <th>CUMPLE_CON_NO3</th>\n",
       "      <th>CUMPLE_CON_AS</th>\n",
       "      <th>CUMPLE_CON_CD</th>\n",
       "      <th>CUMPLE_CON_CR</th>\n",
       "      <th>CUMPLE_CON_HG</th>\n",
       "      <th>CUMPLE_CON_PB</th>\n",
       "      <th>CUMPLE_CON_MN</th>\n",
       "      <th>CUMPLE_CON_FE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLAVE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DLAGU6</th>\n",
       "      <td>POZO SAN GIL</td>\n",
       "      <td>LERMA SANTIAGO PACIFICO</td>\n",
       "      <td>AGUASCALIENTES</td>\n",
       "      <td>ASIENTOS</td>\n",
       "      <td>VALLE DE CHICALOTE</td>\n",
       "      <td>POZO</td>\n",
       "      <td>-102.02210</td>\n",
       "      <td>22.20887</td>\n",
       "      <td>2020</td>\n",
       "      <td>229.990</td>\n",
       "      <td>Alta</td>\n",
       "      <td>940.0</td>\n",
       "      <td>Permisible para riego</td>\n",
       "      <td>NaN</td>\n",
       "      <td>603.6</td>\n",
       "      <td>Cultivos sensibles</td>\n",
       "      <td>Potable - Dulce</td>\n",
       "      <td>0.9766</td>\n",
       "      <td>Potable - Optima</td>\n",
       "      <td>213.732</td>\n",
       "      <td>Potable - Dura</td>\n",
       "      <td>&lt;1.1</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>4.184656</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>Apta como FAAP</td>\n",
       "      <td>&lt;0.003</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>&lt;0.005</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>&lt;0.0005</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>&lt;0.005</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>&lt;0.0015</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>Verde</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLAGU6516</th>\n",
       "      <td>POZO R013 CAADA HONDA</td>\n",
       "      <td>LERMA SANTIAGO PACIFICO</td>\n",
       "      <td>AGUASCALIENTES</td>\n",
       "      <td>AGUASCALIENTES</td>\n",
       "      <td>VALLE DE CHICALOTE</td>\n",
       "      <td>POZO</td>\n",
       "      <td>-102.20075</td>\n",
       "      <td>21.99958</td>\n",
       "      <td>2020</td>\n",
       "      <td>231.990</td>\n",
       "      <td>Alta</td>\n",
       "      <td>608.0</td>\n",
       "      <td>Buena para riego</td>\n",
       "      <td>NaN</td>\n",
       "      <td>445.4</td>\n",
       "      <td>Excelente para riego</td>\n",
       "      <td>Potable - Dulce</td>\n",
       "      <td>0.9298</td>\n",
       "      <td>Potable - Optima</td>\n",
       "      <td>185.0514</td>\n",
       "      <td>Potable - Dura</td>\n",
       "      <td>&lt;1.1</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>5.75011</td>\n",
       "      <td>Potable - Buena calidad</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>Apta como FAAP</td>\n",
       "      <td>&lt;0.003</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>&lt;0.005</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>&lt;0.0005</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>&lt;0.005</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>&lt;0.0015</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>&lt;0.025</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>Verde</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLAGU7</th>\n",
       "      <td>POZO COSIO</td>\n",
       "      <td>LERMA SANTIAGO PACIFICO</td>\n",
       "      <td>AGUASCALIENTES</td>\n",
       "      <td>COSIO</td>\n",
       "      <td>VALLE DE AGUASCALIENTES</td>\n",
       "      <td>POZO</td>\n",
       "      <td>-102.28801</td>\n",
       "      <td>22.36685</td>\n",
       "      <td>2020</td>\n",
       "      <td>204.920</td>\n",
       "      <td>Alta</td>\n",
       "      <td>532.0</td>\n",
       "      <td>Buena para riego</td>\n",
       "      <td>NaN</td>\n",
       "      <td>342</td>\n",
       "      <td>Excelente para riego</td>\n",
       "      <td>Potable - Dulce</td>\n",
       "      <td>1.8045</td>\n",
       "      <td>Alta</td>\n",
       "      <td>120.719</td>\n",
       "      <td>Potable - Dura</td>\n",
       "      <td>&lt;1.1</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>1.449803</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>0.037</td>\n",
       "      <td>No apta como FAAP</td>\n",
       "      <td>&lt;0.003</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>&lt;0.005</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>&lt;0.0005</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>&lt;0.005</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>&lt;0.0015</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>&lt;0.025</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>Rojo</td>\n",
       "      <td>FLUO,AS,</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>NO</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>NO</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLAGU9</th>\n",
       "      <td>POZO EL SALITRILLO</td>\n",
       "      <td>LERMA SANTIAGO PACIFICO</td>\n",
       "      <td>AGUASCALIENTES</td>\n",
       "      <td>RINCON DE ROMOS</td>\n",
       "      <td>VALLE DE AGUASCALIENTES</td>\n",
       "      <td>POZO</td>\n",
       "      <td>-102.29449</td>\n",
       "      <td>22.18435</td>\n",
       "      <td>2020</td>\n",
       "      <td>327.000</td>\n",
       "      <td>Alta</td>\n",
       "      <td>686.0</td>\n",
       "      <td>Buena para riego</td>\n",
       "      <td>NaN</td>\n",
       "      <td>478.6</td>\n",
       "      <td>Excelente para riego</td>\n",
       "      <td>Potable - Dulce</td>\n",
       "      <td>1.1229</td>\n",
       "      <td>Potable - Optima</td>\n",
       "      <td>199.879</td>\n",
       "      <td>Potable - Dura</td>\n",
       "      <td>&lt;1.1</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>1.258597</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>Apta como FAAP</td>\n",
       "      <td>&lt;0.003</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>0.005</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>&lt;0.0005</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>&lt;0.005</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>&lt;0.0015</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>&lt;0.025</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>Verde</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLBAJ107</th>\n",
       "      <td>RANCHO EL TECOLOTE</td>\n",
       "      <td>PENINSULA DE BAJA CALIFORNIA</td>\n",
       "      <td>BAJA CALIFORNIA SUR</td>\n",
       "      <td>LA PAZ</td>\n",
       "      <td>TODOS SANTOS</td>\n",
       "      <td>POZO</td>\n",
       "      <td>-110.24480</td>\n",
       "      <td>23.45138</td>\n",
       "      <td>2020</td>\n",
       "      <td>309.885</td>\n",
       "      <td>Alta</td>\n",
       "      <td>1841.0</td>\n",
       "      <td>Permisible para riego</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1179</td>\n",
       "      <td>Cultivos con manejo especial</td>\n",
       "      <td>Ligeramente salobres</td>\n",
       "      <td>0.2343</td>\n",
       "      <td>Baja</td>\n",
       "      <td>476.9872</td>\n",
       "      <td>Potable - Dura</td>\n",
       "      <td>291</td>\n",
       "      <td>Aceptable</td>\n",
       "      <td>15.672251</td>\n",
       "      <td>No apta como FAAP</td>\n",
       "      <td>&lt;0.01</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>&lt;0.003</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>&lt;0.005</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>&lt;0.0005</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>&lt;0.005</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>&lt;0.0015</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>&lt;0.025</td>\n",
       "      <td>Potable - Excelente</td>\n",
       "      <td>Rojo</td>\n",
       "      <td>NO3,</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>NO</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           SITIO           ORGANISMO_DE_CUENCA  \\\n",
       "CLAVE                                                            \n",
       "DLAGU6              POZO SAN GIL       LERMA SANTIAGO PACIFICO   \n",
       "DLAGU6516  POZO R013 CAADA HONDA       LERMA SANTIAGO PACIFICO   \n",
       "DLAGU7                POZO COSIO       LERMA SANTIAGO PACIFICO   \n",
       "DLAGU9        POZO EL SALITRILLO       LERMA SANTIAGO PACIFICO   \n",
       "DLBAJ107      RANCHO EL TECOLOTE  PENINSULA DE BAJA CALIFORNIA   \n",
       "\n",
       "                        ESTADO        MUNICIPIO                 ACUIFERO  \\\n",
       "CLAVE                                                                      \n",
       "DLAGU6          AGUASCALIENTES         ASIENTOS       VALLE DE CHICALOTE   \n",
       "DLAGU6516       AGUASCALIENTES   AGUASCALIENTES       VALLE DE CHICALOTE   \n",
       "DLAGU7          AGUASCALIENTES            COSIO  VALLE DE AGUASCALIENTES   \n",
       "DLAGU9          AGUASCALIENTES  RINCON DE ROMOS  VALLE DE AGUASCALIENTES   \n",
       "DLBAJ107   BAJA CALIFORNIA SUR           LA PAZ             TODOS SANTOS   \n",
       "\n",
       "          SUBTIPO   LONGITUD   LATITUD  PERIODO  ALC_mg/L CALIDAD_ALC  \\\n",
       "CLAVE                                                                   \n",
       "DLAGU6       POZO -102.02210  22.20887     2020   229.990        Alta   \n",
       "DLAGU6516    POZO -102.20075  21.99958     2020   231.990        Alta   \n",
       "DLAGU7       POZO -102.28801  22.36685     2020   204.920        Alta   \n",
       "DLAGU9       POZO -102.29449  22.18435     2020   327.000        Alta   \n",
       "DLBAJ107     POZO -110.24480  23.45138     2020   309.885        Alta   \n",
       "\n",
       "           CONDUCT_mS/cm         CALIDAD_CONDUC  SDT_mg/L SDT_M_mg/L  \\\n",
       "CLAVE                                                                  \n",
       "DLAGU6             940.0  Permisible para riego       NaN      603.6   \n",
       "DLAGU6516          608.0       Buena para riego       NaN      445.4   \n",
       "DLAGU7             532.0       Buena para riego       NaN        342   \n",
       "DLAGU9             686.0       Buena para riego       NaN      478.6   \n",
       "DLBAJ107          1841.0  Permisible para riego       NaN       1179   \n",
       "\n",
       "                         CALIDAD_SDT_ra     CALIDAD_SDT_salin FLUORUROS_mg/L  \\\n",
       "CLAVE                                                                          \n",
       "DLAGU6               Cultivos sensibles       Potable - Dulce         0.9766   \n",
       "DLAGU6516          Excelente para riego       Potable - Dulce         0.9298   \n",
       "DLAGU7             Excelente para riego       Potable - Dulce         1.8045   \n",
       "DLAGU9             Excelente para riego       Potable - Dulce         1.1229   \n",
       "DLBAJ107   Cultivos con manejo especial  Ligeramente salobres         0.2343   \n",
       "\n",
       "               CALIDAD_FLUO  DUR_mg/L     CALIDAD_DUR COLI_FEC_NMP/100_mL  \\\n",
       "CLAVE                                                                       \n",
       "DLAGU6     Potable - Optima   213.732  Potable - Dura                <1.1   \n",
       "DLAGU6516  Potable - Optima  185.0514  Potable - Dura                <1.1   \n",
       "DLAGU7                 Alta   120.719  Potable - Dura                <1.1   \n",
       "DLAGU9     Potable - Optima   199.879  Potable - Dura                <1.1   \n",
       "DLBAJ107               Baja  476.9872  Potable - Dura                 291   \n",
       "\n",
       "              CALIDAD_COLI_FEC N_NO3_mg/L            CALIDAD_N_NO3  \\\n",
       "CLAVE                                                                \n",
       "DLAGU6     Potable - Excelente   4.184656      Potable - Excelente   \n",
       "DLAGU6516  Potable - Excelente    5.75011  Potable - Buena calidad   \n",
       "DLAGU7     Potable - Excelente   1.449803      Potable - Excelente   \n",
       "DLAGU9     Potable - Excelente   1.258597      Potable - Excelente   \n",
       "DLBAJ107             Aceptable  15.672251        No apta como FAAP   \n",
       "\n",
       "          AS_TOT_mg/L           CALIDAD_AS CD_TOT_mg/L           CALIDAD_CD  \\\n",
       "CLAVE                                                                         \n",
       "DLAGU6         0.0161       Apta como FAAP      <0.003  Potable - Excelente   \n",
       "DLAGU6516      0.0134       Apta como FAAP      <0.003  Potable - Excelente   \n",
       "DLAGU7          0.037    No apta como FAAP      <0.003  Potable - Excelente   \n",
       "DLAGU9         0.0154       Apta como FAAP      <0.003  Potable - Excelente   \n",
       "DLBAJ107        <0.01  Potable - Excelente      <0.003  Potable - Excelente   \n",
       "\n",
       "          CR_TOT_mg/L           CALIDAD_CR HG_TOT_mg/L           CALIDAD_HG  \\\n",
       "CLAVE                                                                         \n",
       "DLAGU6         <0.005  Potable - Excelente     <0.0005  Potable - Excelente   \n",
       "DLAGU6516      <0.005  Potable - Excelente     <0.0005  Potable - Excelente   \n",
       "DLAGU7         <0.005  Potable - Excelente     <0.0005  Potable - Excelente   \n",
       "DLAGU9          0.005  Potable - Excelente     <0.0005  Potable - Excelente   \n",
       "DLBAJ107       <0.005  Potable - Excelente     <0.0005  Potable - Excelente   \n",
       "\n",
       "          PB_TOT_mg/L           CALIDAD_PB MN_TOT_mg/L           CALIDAD_MN  \\\n",
       "CLAVE                                                                         \n",
       "DLAGU6         <0.005  Potable - Excelente     <0.0015  Potable - Excelente   \n",
       "DLAGU6516      <0.005  Potable - Excelente     <0.0015  Potable - Excelente   \n",
       "DLAGU7         <0.005  Potable - Excelente     <0.0015  Potable - Excelente   \n",
       "DLAGU9         <0.005  Potable - Excelente     <0.0015  Potable - Excelente   \n",
       "DLBAJ107       <0.005  Potable - Excelente     <0.0015  Potable - Excelente   \n",
       "\n",
       "          FE_TOT_mg/L           CALIDAD_FE SEMAFORO CONTAMINANTES  \\\n",
       "CLAVE                                                               \n",
       "DLAGU6         0.0891  Potable - Excelente    Verde           NaN   \n",
       "DLAGU6516      <0.025  Potable - Excelente    Verde           NaN   \n",
       "DLAGU7         <0.025  Potable - Excelente     Rojo      FLUO,AS,   \n",
       "DLAGU9         <0.025  Potable - Excelente    Verde           NaN   \n",
       "DLBAJ107       <0.025  Potable - Excelente     Rojo          NO3,   \n",
       "\n",
       "          CUMPLE_CON_ALC CUMPLE_CON_COND CUMPLE_CON_SDT_ra  \\\n",
       "CLAVE                                                        \n",
       "DLAGU6                SI              SI                SI   \n",
       "DLAGU6516             SI              SI                SI   \n",
       "DLAGU7                SI              SI                SI   \n",
       "DLAGU9                SI              SI                SI   \n",
       "DLBAJ107              SI              SI                SI   \n",
       "\n",
       "          CUMPLE_CON_SDT_salin CUMPLE_CON_FLUO CUMPLE_CON_DUR CUMPLE_CON_CF  \\\n",
       "CLAVE                                                                         \n",
       "DLAGU6                      SI              SI             SI            SI   \n",
       "DLAGU6516                   SI              SI             SI            SI   \n",
       "DLAGU7                      SI              NO             SI            SI   \n",
       "DLAGU9                      SI              SI             SI            SI   \n",
       "DLBAJ107                    SI              SI             SI            SI   \n",
       "\n",
       "          CUMPLE_CON_NO3 CUMPLE_CON_AS CUMPLE_CON_CD CUMPLE_CON_CR  \\\n",
       "CLAVE                                                                \n",
       "DLAGU6                SI            SI            SI            SI   \n",
       "DLAGU6516             SI            SI            SI            SI   \n",
       "DLAGU7                SI            NO            SI            SI   \n",
       "DLAGU9                SI            SI            SI            SI   \n",
       "DLBAJ107              NO            SI            SI            SI   \n",
       "\n",
       "          CUMPLE_CON_HG CUMPLE_CON_PB CUMPLE_CON_MN CUMPLE_CON_FE  \n",
       "CLAVE                                                              \n",
       "DLAGU6               SI            SI            SI            SI  \n",
       "DLAGU6516            SI            SI            SI            SI  \n",
       "DLAGU7               SI            SI            SI            SI  \n",
       "DLAGU9               SI            SI            SI            SI  \n",
       "DLBAJ107             SI            SI            SI            SI  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df contiene nuestro dataframe original\n",
    "df = pd.read_csv('Datos_de_calidad_del_agua_2020/Datos_de_calidad_del_agua_de_sitios_de_monitoreo_de_aguas_subterraneas_2020.csv', \n",
    "                    index_col=0,encoding='utf-8',encoding_errors='ignore')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline(steps = [('impMediana', SimpleImputer(missing_values=np.nan, strategy= 'constant', fill_value = 0)),\n",
    "                                 ('escalaNum', MinMaxScaler(feature_range=(1,2)))])   \n",
    "num_pipeline_nombres = ['LONGITUD','LATITUD','ALC_mg/L','CONDUCT_mS/cm','SDT_M_mg/L',\n",
    "'FLUORUROS_mg/L','DUR_mg/L','COLI_FEC_NMP/100_mL','N_NO3_mg/L','AS_TOT_mg/L','CD_TOT_mg/L','CR_TOT_mg/L','HG_TOT_mg/L','PB_TOT_mg/L','MN_TOT_mg/L','FE_TOT_mg/L']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checar distribucion de los datos continuos en histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['CALIDAD_MN']]\n",
    "X = df.drop(columns='CALIDAD_MN')\n",
    "\n",
    "\n",
    "Xtv, Xtest, ytv, ytest = train_test_split(X, y, test_size=.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '<25'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\genar\\OneDrive\\maestria\\ciencia de datos\\actividades-del-projecto-equipo_167\\semana 9\\Limpieza, análisis, visualización y kmeans.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/genar/OneDrive/maestria/ciencia%20de%20datos/actividades-del-projecto-equipo_167/semana%209/Limpieza%2C%20an%C3%A1lisis%2C%20visualizaci%C3%B3n%20y%20kmeans.ipynb#X63sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m preprocessor \u001b[39m=\u001b[39m ColumnTransformer(transformers \u001b[39m=\u001b[39m [(\u001b[39m'\u001b[39m\u001b[39mnumpipe\u001b[39m\u001b[39m'\u001b[39m, num_pipeline, num_pipeline_nombres),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/genar/OneDrive/maestria/ciencia%20de%20datos/actividades-del-projecto-equipo_167/semana%209/Limpieza%2C%20an%C3%A1lisis%2C%20visualizaci%C3%B3n%20y%20kmeans.ipynb#X63sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                                                         \u001b[39m#('catimp', catImp_pipeline, catImp_pipeline_nombres),\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/genar/OneDrive/maestria/ciencia%20de%20datos/actividades-del-projecto-equipo_167/semana%209/Limpieza%2C%20an%C3%A1lisis%2C%20visualizaci%C3%B3n%20y%20kmeans.ipynb#X63sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                                                         \u001b[39m#('catohe', catOHE_pipeline, catOHE_pipeline_nombres)],\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/genar/OneDrive/maestria/ciencia%20de%20datos/actividades-del-projecto-equipo_167/semana%209/Limpieza%2C%20an%C3%A1lisis%2C%20visualizaci%C3%B3n%20y%20kmeans.ipynb#X63sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                                         ], remainder\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/genar/OneDrive/maestria/ciencia%20de%20datos/actividades-del-projecto-equipo_167/semana%209/Limpieza%2C%20an%C3%A1lisis%2C%20visualizaci%C3%B3n%20y%20kmeans.ipynb#X63sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m XtrainvalTransf \u001b[39m=\u001b[39m preprocessor\u001b[39m.\u001b[39;49mfit_transform(Xtv)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/genar/OneDrive/maestria/ciencia%20de%20datos/actividades-del-projecto-equipo_167/semana%209/Limpieza%2C%20an%C3%A1lisis%2C%20visualizaci%C3%B3n%20y%20kmeans.ipynb#X63sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m#optional\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/genar/OneDrive/maestria/ciencia%20de%20datos/actividades-del-projecto-equipo_167/semana%209/Limpieza%2C%20an%C3%A1lisis%2C%20visualizaci%C3%B3n%20y%20kmeans.ipynb#X63sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m XtrainvalTransf_asDataFrame \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(XtrainvalTransf)\n",
      "File \u001b[1;32mc:\\Users\\genar\\.conda\\envs\\master_DS\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:690\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_column_callables(X)\n\u001b[0;32m    688\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_remainder(X)\n\u001b[1;32m--> 690\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_transform(X, y, _fit_transform_one)\n\u001b[0;32m    692\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m result:\n\u001b[0;32m    693\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_fitted_transformers([])\n",
      "File \u001b[1;32mc:\\Users\\genar\\.conda\\envs\\master_DS\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:621\u001b[0m, in \u001b[0;36mColumnTransformer._fit_transform\u001b[1;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[0;32m    615\u001b[0m transformers \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[0;32m    616\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(\n\u001b[0;32m    617\u001b[0m         fitted\u001b[39m=\u001b[39mfitted, replace_strings\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, column_as_strings\u001b[39m=\u001b[39mcolumn_as_strings\n\u001b[0;32m    618\u001b[0m     )\n\u001b[0;32m    619\u001b[0m )\n\u001b[0;32m    620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m     \u001b[39mreturn\u001b[39;00m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[0;32m    622\u001b[0m         delayed(func)(\n\u001b[0;32m    623\u001b[0m             transformer\u001b[39m=\u001b[39;49mclone(trans) \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m fitted \u001b[39melse\u001b[39;49;00m trans,\n\u001b[0;32m    624\u001b[0m             X\u001b[39m=\u001b[39;49m_safe_indexing(X, column, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[0;32m    625\u001b[0m             y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    626\u001b[0m             weight\u001b[39m=\u001b[39;49mweight,\n\u001b[0;32m    627\u001b[0m             message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mColumnTransformer\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    628\u001b[0m             message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(name, idx, \u001b[39mlen\u001b[39;49m(transformers)),\n\u001b[0;32m    629\u001b[0m         )\n\u001b[0;32m    630\u001b[0m         \u001b[39mfor\u001b[39;49;00m idx, (name, trans, column, weight) \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(transformers, \u001b[39m1\u001b[39;49m)\n\u001b[0;32m    631\u001b[0m     )\n\u001b[0;32m    632\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    633\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(e):\n",
      "File \u001b[1;32mc:\\Users\\genar\\.conda\\envs\\master_DS\\lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\genar\\.conda\\envs\\master_DS\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\genar\\.conda\\envs\\master_DS\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\genar\\.conda\\envs\\master_DS\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\genar\\.conda\\envs\\master_DS\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\genar\\.conda\\envs\\master_DS\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\genar\\.conda\\envs\\master_DS\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\genar\\.conda\\envs\\master_DS\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\genar\\.conda\\envs\\master_DS\\lib\\site-packages\\sklearn\\pipeline.py:870\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    869\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 870\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit_transform(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    871\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    872\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\genar\\.conda\\envs\\master_DS\\lib\\site-packages\\sklearn\\pipeline.py:422\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    420\u001b[0m fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m    421\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(last_step, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 422\u001b[0m     \u001b[39mreturn\u001b[39;00m last_step\u001b[39m.\u001b[39mfit_transform(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    423\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    424\u001b[0m     \u001b[39mreturn\u001b[39;00m last_step\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\u001b[39m.\u001b[39mtransform(Xt)\n",
      "File \u001b[1;32mc:\\Users\\genar\\.conda\\envs\\master_DS\\lib\\site-packages\\sklearn\\base.py:867\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    864\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    865\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    866\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    868\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    869\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\genar\\.conda\\envs\\master_DS\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:420\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[39m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 420\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y)\n",
      "File \u001b[1;32mc:\\Users\\genar\\.conda\\envs\\master_DS\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:457\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    452\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMinMaxScaler does not support sparse input. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    453\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConsider using MaxAbsScaler instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    454\u001b[0m     )\n\u001b[0;32m    456\u001b[0m first_pass \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_samples_seen_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 457\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    458\u001b[0m     X,\n\u001b[0;32m    459\u001b[0m     reset\u001b[39m=\u001b[39;49mfirst_pass,\n\u001b[0;32m    460\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[0;32m    461\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    462\u001b[0m )\n\u001b[0;32m    464\u001b[0m data_min \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnanmin(X, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m    465\u001b[0m data_max \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnanmax(X, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\genar\\.conda\\envs\\master_DS\\lib\\site-packages\\sklearn\\base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\genar\\.conda\\envs\\master_DS\\lib\\site-packages\\sklearn\\utils\\validation.py:856\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    854\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    855\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 856\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    857\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    858\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    860\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '<25'"
     ]
    }
   ],
   "source": [
    "preprocessor = ColumnTransformer(transformers = [('numpipe', num_pipeline, num_pipeline_nombres),\n",
    "                                                        #('catimp', catImp_pipeline, catImp_pipeline_nombres),\n",
    "                                                        #('catohe', catOHE_pipeline, catOHE_pipeline_nombres)],\n",
    "                                        ], remainder='passthrough')\n",
    "\n",
    "\n",
    "XtrainvalTransf = preprocessor.fit_transform(Xtv)\n",
    "\n",
    "#optional\n",
    "XtrainvalTransf_asDataFrame = pd.DataFrame(XtrainvalTransf)\n",
    "#New_Labels=[]\n",
    "#XtrainvalTransf_asDataFrame.columns = New_Labels\n",
    "XtrainvalTransf_asDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "XtrainvalTransf_asDataFrame.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui se observa, que el problema de datos nulos existe en todas las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "scatter_matrix(df, alpha=0.2, figsize=(6, 6), diagonal='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificamos cuales columnas son aquellas que contienen renglones vacios\n",
    "df.isnull().any()\n",
    "#df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como primer paso de limpieza del dataframe, vamos a eliminar las 2 columnas que no se consideran relevantes para el estudio:\n",
    "\n",
    "    X2: Gender (1 = male; 2 = female)\n",
    "    X4: Marital status (1 = married; 2 = single; 3 = others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este dataframe, ya no contiene las columnas irrelevantes\n",
    "df_without_X2_X4 = df.drop(['X2', 'X4',], axis = 1)\n",
    "df_without_X2_X4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a renombrar las columnas a sus nombres explicados en el .txt, para entender mejor que numero estamos leyendo durante las siguientes fases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_X2_X4 = df_without_X2_X4.rename(columns={\"X1\":\"Amount of the given credit\"})\n",
    "df_without_X2_X4 = df_without_X2_X4.rename(columns={\"X3\":\"Education\"})\n",
    "df_without_X2_X4 = df_without_X2_X4.rename(columns={\"X5\":\"Age\"})\n",
    "df_without_X2_X4 = df_without_X2_X4.rename(columns={\"X6\":\"Repayment September, 2005\"})\n",
    "df_without_X2_X4 = df_without_X2_X4.rename(columns={\"X7\":\"Repayment August, 2005\"})\n",
    "df_without_X2_X4 = df_without_X2_X4.rename(columns={\"X8\":\"Repayment July, 2005\"})\n",
    "df_without_X2_X4 = df_without_X2_X4.rename(columns={\"X9\":\"Repayment June, 2005\"})\n",
    "df_without_X2_X4 = df_without_X2_X4.rename(columns={\"X10\":\"Repayment May, 2005\"})\n",
    "df_without_X2_X4 = df_without_X2_X4.rename(columns={\"X11\":\"Repayment April, 2005\"})\n",
    "df_without_X2_X4 = df_without_X2_X4.rename(columns={\"X12\":\"Bill September, 2005\"})\n",
    "df_without_X2_X4 = df_without_X2_X4.rename(columns={\"X13\":\"Bill August, 2005\"})\n",
    "df_without_X2_X4 = df_without_X2_X4.rename(columns={\"X14\":\"Bill July, 2005\"})\n",
    "df_without_X2_X4 = df_without_X2_X4.rename(columns={\"X15\":\"Bill June, 2005\"})\n",
    "df_without_X2_X4 = df_without_X2_X4.rename(columns={\"X16\":\"Bill May, 2005\"})\n",
    "df_without_X2_X4 = df_without_X2_X4.rename(columns={\"X17\":\"Bill April, 2005\"})\n",
    "df_without_X2_X4 = df_without_X2_X4.rename(columns={\"X18\":\"amount paid  September, 2005\"})\n",
    "df_without_X2_X4 = df_without_X2_X4.rename(columns={\"X19\":\"amount paid  August, 2005\"})\n",
    "df_without_X2_X4 = df_without_X2_X4.rename(columns={\"X20\":\"amount paid  July, 2005\"})\n",
    "df_without_X2_X4 = df_without_X2_X4.rename(columns={\"X21\":\"amount paid  June, 2005\"})\n",
    "df_without_X2_X4 = df_without_X2_X4.rename(columns={\"X22\":\"amount paid  May, 2005\"})\n",
    "df_without_X2_X4 = df_without_X2_X4.rename(columns={\"X23\":\"amount paid  April, 2005\"})\n",
    "df_without_X2_X4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionando la mejor técnicas para manejar los datos faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como segundo paso de limpieza, vamos a eliminar renglones con datos vacios, como el ejemplo arriba mostrado donde el ID 19, no contenia datos en las columnas X12-X17.\n",
    "Una vez que eliminemos esos renglones, veremos que tanto se reduce nuestro dataframe, para asi tomar una decision de que técnica para manejo de datos faltantes utilizaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping rows with NaN values on some column (at least 1)\n",
    "df_no_empty_rows = df_without_X2_X4.dropna()\n",
    "df_no_empty_rows\n",
    "\n",
    "#OPCIONAL En caso de querer definir un threshold\n",
    "#df_no_empty_rows_with_threshold.dropna(thresh=4, inplace = True) # In a row, it needs at least 4 nan values is needed, to maintain in df\n",
    "#df_no_empty_rows_with_threshold # in case of column  add   axis=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We see that instead of 3000 rows (original dataframe) we only have now 29,958 rows on this new dataframe\n",
    "#Este dataframe elimina el renglon completo si es que alguna de las variables (X) es nula\n",
    "# Solamente 42 de 3000 renglones (1.4%) se pierden al utilizar la técnica de Eliminación por lista.\n",
    "df_no_empty_rows.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Este sera nuestro dataframe para el ejercicio de la Semana 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_eliminacion_por_lista = df_no_empty_rows\n",
    "#df_eliminacion_por_lista.index.name = None\n",
    "df_eliminacion_por_lista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!!!!!!!!!!!!!!!!!!!!!!!!! Primero que nada, debemos de normalizar todos nuestros datos de variables INDEPENDIENTES  !!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Sklearn & MinMax Scalar.\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_normalized = df_eliminacion_por_lista.copy()\n",
    "\n",
    "#La variable dependiente no se debe de considerar en el dataset de PCA\n",
    "df_normalized.drop(columns='Y',inplace=True)\n",
    "\n",
    "df_normalized.iloc[:,0:] = scaler.fit_transform(df_normalized.iloc[:,0:].to_numpy())\n",
    "df_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 1: Determine el número mínimo de componentes principales que representan la mayor parte de la variación en sus datos\n",
    "\n",
    "Utilice la proporción acumulada de la varianza que explican los componentes para determinar la cantidad de varianza que explican los componentes principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each clientID, the data include 21 numerical variables, and we are interested in reducing this dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pcs = PCA()\n",
    "pcs.fit(df_normalized)\n",
    "pcsSummary_df = pd.DataFrame({'Standard deviation': np.sqrt(pcs.explained_variance_),\n",
    "                             'Proportion of variance': pcs.explained_variance_ratio_,\n",
    "                             'Cumulative proportion': np.cumsum(pcs.explained_variance_ratio_)\n",
    "                             })\n",
    "pcsSummary_df = pcsSummary_df.transpose()\n",
    "pcsSummary_df.columns = ['PC{}'.format(i) for i in range(1, len(pcsSummary_df.columns) + 1)]\n",
    "pcsSummary_df = pcsSummary_df.round(4)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pcsSummary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To display how much components do we need to explain more than 90% of variance\n",
    "\n",
    "#12 Principal components are needed\n",
    "pcsSummary_df.iloc[2,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PC_components = np.arange(pcs.n_components_) + 1\n",
    "#PC_components\n",
    "\n",
    "_ = sns.set(style = 'whitegrid', \n",
    "            font_scale = 1.2\n",
    "            )\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "_ = sns.barplot(x = PC_components, \n",
    "                y = pcs.explained_variance_ratio_, \n",
    "                color = 'b'\n",
    "                )\n",
    "\n",
    "_ = sns.lineplot(x = PC_components-1, \n",
    "                 y = np.cumsum(pcs.explained_variance_ratio_), \n",
    "                 color = 'black', \n",
    "                 linestyle = '-', \n",
    "                 linewidth = 2, \n",
    "                 marker = 'o', \n",
    "                 markersize = 8\n",
    "                 )\n",
    "\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('N-th Principal Component')\n",
    "plt.ylabel('Variance Explained')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION:\n",
    "Necesitamos al menos 11 componentes para explicar mas del 90% de la varianza de la coleccion de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 2: Interprete cada componente principal en términos de las variables originales\n",
    "\n",
    "Examine la magnitud y la dirección de los coeficientes de las variables originales.\n",
    "Nota: Cuanto mayor sea el valor absoluto del coeficiente, más importante será la variable correspondiente en el cálculo del componente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcsComponents_df = pd.DataFrame(pcs.components_.transpose(), \n",
    "                                columns = pcsSummary_df.columns,\n",
    "                                index = df_normalized.columns\n",
    "                                )\n",
    "pcsComponents_df.iloc[:,:11].head()\n",
    "#pcsComponents_df.sort_values(by='PC2', inplace=False, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora debemos de buscar la magnitud y direccion de las variables originales, es decir cual influye mas y cual influye menos, en cada uno de los componentes principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC1 = pcsComponents_df['PC1'].abs().idxmax()                  \n",
    "print('El valor original mas relevante para PC1 es: ', PC1, \", con un peso de: \", pcsComponents_df.abs().loc[PC1,['PC1']].values)\n",
    "PC2 = pcsComponents_df['PC2'].abs().idxmax()                  \n",
    "print('El valor original mas relevante para PC2 es: ', PC2, \", con un peso de: \", pcsComponents_df.abs().loc[PC2,['PC2']].values)\n",
    "PC3 = pcsComponents_df['PC3'].abs().idxmax()                  \n",
    "print('El valor original mas relevante para PC3 es: ', PC3, \", con un peso de: \", pcsComponents_df.abs().loc[PC3,['PC3']].values)\n",
    "PC4 = pcsComponents_df['PC4'].abs().idxmax()                  \n",
    "print('El valor original mas relevante para PC4 es: ', PC4, \", con un peso de: \", pcsComponents_df.abs().loc[PC4,['PC4']].values)\n",
    "PC5 = pcsComponents_df['PC5'].abs().idxmax()                  \n",
    "print('El valor original mas relevante para PC5 es: ', PC5, \", con un peso de: \", pcsComponents_df.abs().loc[PC5,['PC5']].values)\n",
    "PC6 = pcsComponents_df['PC6'].abs().idxmax()                  \n",
    "print('El valor original mas relevante para PC6 es: ', PC6, \", con un peso de: \", pcsComponents_df.abs().loc[PC6,['PC6']].values)\n",
    "PC7 = pcsComponents_df['PC7'].abs().idxmax()                  \n",
    "print('El valor original mas relevante para PC7 es: ', PC7, \", con un peso de: \", pcsComponents_df.abs().loc[PC7,['PC7']].values)\n",
    "PC8 = pcsComponents_df['PC8'].abs().idxmax()                  \n",
    "print('El valor original mas relevante para PC8 es: ', PC8, \", con un peso de: \", pcsComponents_df.abs().loc[PC8,['PC8']].values)\n",
    "PC9 = pcsComponents_df['PC9'].abs().idxmax()                  \n",
    "print('El valor original mas relevante para PC9 es: ', PC9, \", con un peso de: \", pcsComponents_df.abs().loc[PC9,['PC9']].values)\n",
    "PC10 = pcsComponents_df['PC10'].abs().idxmax()                  \n",
    "print('El valor original mas relevante para PC10 es: ', PC10, \", con un peso de: \", pcsComponents_df.abs().loc[PC10,['PC10']].values)\n",
    "PC11 = pcsComponents_df['PC11'].abs().idxmax()                  \n",
    "print('El valor original mas relevante para PC11 es: ', PC11, \", con un peso de: \", pcsComponents_df.abs().loc[PC10,['PC11']].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC1 = pcsComponents_df['PC1'].abs().idxmin()                  \n",
    "print('El valor original menos relevante para PC1 es: ', PC1, \", con un peso de: \", pcsComponents_df.abs().loc[PC1,['PC1']].values)\n",
    "PC2 = pcsComponents_df['PC2'].abs().idxmin()                  \n",
    "print('El valor original menos relevante para PC2 es: ', PC2, \", con un peso de: \", pcsComponents_df.abs().loc[PC2,['PC2']].values)\n",
    "PC3 = pcsComponents_df['PC3'].abs().idxmin()                  \n",
    "print('El valor original menos relevante para PC3 es: ', PC3, \", con un peso de: \", pcsComponents_df.abs().loc[PC3,['PC3']].values)\n",
    "PC4 = pcsComponents_df['PC4'].abs().idxmin()                  \n",
    "print('El valor original menos relevante para PC4 es: ', PC4, \", con un peso de: \", pcsComponents_df.abs().loc[PC4,['PC4']].values)\n",
    "PC5 = pcsComponents_df['PC5'].abs().idxmin()                  \n",
    "print('El valor original menos relevante para PC5 es: ', PC5, \", con un peso de: \", pcsComponents_df.abs().loc[PC5,['PC5']].values)\n",
    "PC6 = pcsComponents_df['PC6'].abs().idxmin()                  \n",
    "print('El valor original menos relevante para PC6 es: ', PC6, \", con un peso de: \", pcsComponents_df.abs().loc[PC6,['PC6']].values)\n",
    "PC7 = pcsComponents_df['PC7'].abs().idxmin()                  \n",
    "print('El valor original menos relevante para PC7 es: ', PC7, \", con un peso de: \", pcsComponents_df.abs().loc[PC7,['PC7']].values)\n",
    "PC8 = pcsComponents_df['PC8'].abs().idxmin()                  \n",
    "print('El valor original menos relevante para PC8 es: ', PC8, \", con un peso de: \", pcsComponents_df.abs().loc[PC8,['PC8']].values)\n",
    "PC9 = pcsComponents_df['PC9'].abs().idxmin()                  \n",
    "print('El valor original menos relevante para PC9 es: ', PC9, \", con un peso de: \", pcsComponents_df.abs().loc[PC9,['PC9']].values)\n",
    "PC10 = pcsComponents_df['PC10'].abs().idxmin()                  \n",
    "print('El valor original menos relevante para PC10 es: ', PC10, \", con un peso de: \", pcsComponents_df.abs().loc[PC10,['PC10']].values)\n",
    "PC11 = pcsComponents_df['PC11'].abs().idxmin()                  \n",
    "print('El valor original menos relevante para PC11 es: ', PC11, \", con un peso de: \", pcsComponents_df.abs().loc[PC10,['PC11']].values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 3: Identifique valores atípicos\n",
    "\n",
    "Realice alguna gráfica de valores atípicos o boxplot para identificar los valores atípicos. Cualquier punto que esté más alejado de la línea de referencia es un valor atípico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcsComponents_df.abs().boxplot(rot=45, fontsize=15,figsize=(15,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#    Parte 2.  Responde las siguientes preguntas en una celda de texto en Jupyter Notebook\n",
    "\n",
    "¿Cuál es el número de componentes mínimo y por qué?\n",
    "\n",
    "    Se necesitan al menos 11 componentes para explicar mas del 90% de la varianza del dataset, por ende 11 seria el numero minimo de componetes a utilizar para crear algun modelo. No hay una regla escrita de cuanto % de varianza se debe de explicar para seleccionar el numero de componentes minimo, sin embargo casi siempre se escoge el 90% como regla de dedo.\n",
    "\n",
    "¿Cuál es la variación de los datos que representan esos componentes?\n",
    "    \n",
    "    El 90.84% de varianza es explicada con 11 componentes.\n",
    "\n",
    "¿Cuál es la pérdida de información después de realizar PCA?\n",
    "\n",
    "    Al utilizar 11 componentes, se perderia 100 - 90.84 = 9.16% de la información.\n",
    "\n",
    "De las variables originales, ¿Cuál tiene mayor y cuál tiene menor importancia en los componentes principales?\n",
    "\n",
    "    Los siguientes valores se obtuvieron CONSIDERANDO los valores atipicos (outliers), no hay evidencia suficiente que muestre que estos datos sean tratados como BIAS, por ende decidimos considerarlos.\n",
    "\n",
    "    El valor original mas relevante para PC1 es:  Bill June, 2005 , con un peso de:  [0.35404466]\n",
    "    El valor original mas relevante para PC2 es:  Repayment June, 2005 , con un peso de:  [0.34520086]\n",
    "    El valor original mas relevante para PC3 es:  amount paid  August, 2005 , con un peso de:  [0.42994087]\n",
    "    El valor original mas relevante para PC4 es:  Education , con un peso de:  [0.70367197]\n",
    "    El valor original mas relevante para PC5 es:  amount paid  May, 2005 , con un peso de:  [0.56117246]\n",
    "    El valor original mas relevante para PC6 es:  amount paid  June, 2005 , con un peso de:  [0.6659325]\n",
    "    El valor original mas relevante para PC7 es:  amount paid  May, 2005 , con un peso de:  [0.70213931]\n",
    "    El valor original mas relevante para PC8 es:  amount paid  April, 2005 , con un peso de:  [0.51483408]\n",
    "    El valor original mas relevante para PC9 es:  amount paid  July, 2005 , con un peso de:  [0.78604804]\n",
    "    El valor original mas relevante para PC10 es:  amount paid  September, 2005 , con un peso de:  [0.72908721]\n",
    "    El valor original mas relevante para PC11 es:  Repayment September, 2005 , con un peso de:  [0.10160137]\n",
    "    \n",
    "\n",
    "    El valor original menos relevante para PC1 es:  Age , con un peso de:  [0.01351372]\n",
    "    El valor original menos relevante para PC2 es:  Age , con un peso de:  [0.06185642]\n",
    "    El valor original menos relevante para PC3 es:  Repayment September, 2005 , con un peso de:  [0.00160321]\n",
    "    El valor original menos relevante para PC4 es:  Bill July, 2005 , con un peso de:  [0.00240161]\n",
    "    El valor original menos relevante para PC5 es:  Repayment April, 2005 , con un peso de:  [0.00254917]\n",
    "    El valor original menos relevante para PC6 es:  Repayment August, 2005 , con un peso de:  [0.00018953]\n",
    "    El valor original menos relevante para PC7 es:  Bill September, 2005 , con un peso de:  [0.00270433]\n",
    "    El valor original menos relevante para PC8 es:  Repayment July, 2005 , con un peso de:  [0.00988628]\n",
    "    El valor original menos relevante para PC9 es:  Bill May, 2005 , con un peso de:  [0.00356531]\n",
    "    El valor original menos relevante para PC10 es:  Education , con un peso de:  [0.00107573]\n",
    "    El valor original menos relevante para PC11 es:  Bill July, 2005 , con un peso de:  [0.19300396]\n",
    "\n",
    "¿Cuándo se recomienda realizar un PCA y qué beneficios ofrece para Machine Learning?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "7013c1f5cfac78860b9561fc9df3ff402d5c67bd3c72110b8d06085e160a3518"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
